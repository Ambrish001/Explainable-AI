{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Defend_Adversarial_Attacks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKM_Mpoq2PuU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t# initialize the model along with the input shape\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\t\t# first CONV => RELU => BN layer set\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\t# second CONV => RELU => BN layer set\n",
        "\t\tmodel.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\t# first (and only) set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(128))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ],
      "metadata": {
        "id": "qAg-RRkE_oOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import MSE\n",
        "import tensorflow as tf\n",
        "def generate_image_adversary(model, image, label, eps=2 / 255.0):\n",
        "\t# cast the image\n",
        "\timage = tf.cast(image, tf.float32)\n",
        "\t# record our gradients\n",
        "\twith tf.GradientTape() as tape:\n",
        "\t\t# explicitly indicate that our image should be tacked for\n",
        "\t\t# gradient updates\n",
        "\t\ttape.watch(image)\n",
        "\t\t# use our model to make predictions on the input image and\n",
        "\t\t# then compute the loss\n",
        "\t\tpred = model(image)\n",
        "\t\tloss = MSE(label, pred)\n",
        "\t# calculate the gradients of loss with respect to the image, then\n",
        "\t# compute the sign of the gradient\n",
        "\tgradient = tape.gradient(loss, image)\n",
        "\tsignedGrad = tf.sign(gradient)\n",
        "\t# construct the image adversary\n",
        "\tadversary = (image + (signedGrad * eps)).numpy()\n",
        "\t# return the image adversary to the calling function\n",
        "\treturn adversary"
      ],
      "metadata": {
        "id": "uLa4dPUBEx5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from .fgsm import generate_image_adversary\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CJdlBM0xFehm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_adversarial_batch(model, total, images, labels, dims,\n",
        "\teps=0.01):\n",
        "\t# unpack the image dimensions into convenience variables\n",
        "\t(h, w, c) = dims\n",
        "\t# we're constructing a data generator here so we need to loop\n",
        "\t# indefinitely\n",
        "\twhile True:\n",
        "\t\t# initialize our perturbed images and labels\n",
        "\t\tperturbImages = []\n",
        "\t\tperturbLabels = []\n",
        "\t\t# randomly sample indexes (without replacement) from the\n",
        "\t\t# input data\n",
        "\t\tidxs = np.random.choice(range(0, len(images)), size=total,\n",
        "\t\t\treplace=False)\n",
        "\t\t# loop over the indexes\n",
        "\t\tfor i in idxs:\n",
        "\t\t\t# grab the current image and label\n",
        "\t\t\timage = images[i]\n",
        "\t\t\tlabel = labels[i]\n",
        "\t\t\t# generate an adversarial image\n",
        "\t\t\tadversary = generate_image_adversary(model,\n",
        "\t\t\t\timage.reshape(1, h, w, c), label, eps=eps)\n",
        "\t\t\t# update our perturbed images and labels lists\n",
        "\t\t\tperturbImages.append(adversary.reshape(h, w, c))\n",
        "\t\t\tperturbLabels.append(label)\n",
        "\t\t# yield the perturbed images and labels\n",
        "\t\tyield (np.array(perturbImages), np.array(perturbLabels))"
      ],
      "metadata": {
        "id": "z480TqfWF55l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mixed_adverserial_batch(model, total, images, labels,\n",
        "\tdims, eps=0.01, split=0.5):\n",
        "\t# unpack the image dimensions into convenience variables\n",
        "\t(h, w, c) = dims\n",
        "\t# compute the total number of training images to keep along with\n",
        "\t# the number of adversarial images to generate\n",
        "\ttotalNormal = int(total * split)\n",
        "\ttotalAdv = int(total * (1 - split))\n",
        "  # we're constructing a data generator so we need to loop\n",
        "\t# indefinitely\n",
        "\twhile True:\n",
        "\t\t# randomly sample indexes (without replacement) from the\n",
        "\t\t# input data and then use those indexes to sample our normal\n",
        "\t\t# images and labels\n",
        "\t\tidxs = np.random.choice(range(0, len(images)),\n",
        "\t\t\tsize=totalNormal, replace=False)\n",
        "\t\tmixedImages = images[idxs]\n",
        "\t\tmixedLabels = labels[idxs]\n",
        "\t\t# again, randomly sample indexes from the input data, this\n",
        "\t\t# time to construct our adversarial images\n",
        "\t\tidxs = np.random.choice(range(0, len(images)), size=totalAdv,\n",
        "\t\t\treplace=False)\n",
        "  \n",
        "    # loop over the indexes\n",
        "\t\tfor i in idxs:\n",
        "\t\t\t# grab the current image and label, then use that data to\n",
        "\t\t\t# generate the adversarial example\n",
        "\t\t\timage = images[i]\n",
        "\t\t\tlabel = labels[i]\n",
        "\t\t\tadversary = generate_image_adversary(model,\n",
        "\t\t\t\timage.reshape(1, h, w, c), label, eps=eps)\n",
        "\t\t\t# update the mixed images and labels lists\n",
        "\t\t\tmixedImages = np.vstack([mixedImages, adversary])\n",
        "\t\t\tmixedLabels = np.vstack([mixedLabels, label])\n",
        "\t\t# shuffle the images and labels together\n",
        "\t\t(mixedImages, mixedLabels) = shuffle(mixedImages, mixedLabels)\n",
        "\t\t# yield the mixed images and labels to the calling function\n",
        "\t\tyield (mixedImages, mixedLabels)  \n",
        " "
      ],
      "metadata": {
        "id": "YJ1AEwrfHxBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "# load MNIST dataset and scale the pixel values to the range [0, 1]\n",
        "print(\"[INFO] loading MNIST dataset...\")\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "# add a channel dimension to the images\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "# one-hot encode our labels\n",
        "trainY = to_categorical(trainY, 10)\n",
        "testY = to_categorical(testY, 10)\n",
        "# initialize our optimizer and model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=1e-3)\n",
        "model = SimpleCNN.build(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "# train the simple CNN on MNIST\n",
        "print(\"[INFO] training network...\")\n",
        "model.fit(trainX, trainY,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tbatch_size=64,\n",
        "\tepochs=20,\n",
        "\tverbose=1)\n",
        "# make predictions on the testing set for the model trained on\n",
        "# non-adversarial images\n",
        "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
        "print(\"[INFO] normal testing images:\")\n",
        "print(\"[INFO] loss: {:.4f}, acc: {:.4f}\\n\".format(loss, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZpF_D-XI7Lg",
        "outputId": "f6b32694-b395-41b9-fb05-9a08f0d5c081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading MNIST dataset...\n",
            "[INFO] compiling model...\n",
            "[INFO] training network...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "938/938 [==============================] - 6s 5ms/step - loss: 0.2019 - accuracy: 0.9390 - val_loss: 0.0604 - val_accuracy: 0.9787\n",
            "Epoch 2/20\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.0768 - accuracy: 0.9769 - val_loss: 0.0445 - val_accuracy: 0.9861\n",
            "Epoch 3/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0575 - accuracy: 0.9821 - val_loss: 0.0437 - val_accuracy: 0.9849\n",
            "Epoch 4/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.0444 - val_accuracy: 0.9860\n",
            "Epoch 5/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0396 - accuracy: 0.9879 - val_loss: 0.0354 - val_accuracy: 0.9887\n",
            "Epoch 6/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0338 - accuracy: 0.9892 - val_loss: 0.0366 - val_accuracy: 0.9886\n",
            "Epoch 7/20\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0296 - accuracy: 0.9906 - val_loss: 0.0378 - val_accuracy: 0.9883\n",
            "Epoch 8/20\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.0337 - val_accuracy: 0.9895\n",
            "Epoch 9/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 0.0320 - val_accuracy: 0.9894\n",
            "Epoch 10/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0461 - val_accuracy: 0.9881\n",
            "Epoch 11/20\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.0385 - val_accuracy: 0.9887\n",
            "Epoch 12/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0386 - val_accuracy: 0.9895\n",
            "Epoch 13/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0338 - val_accuracy: 0.9902\n",
            "Epoch 14/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0352 - val_accuracy: 0.9893\n",
            "Epoch 15/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0404 - val_accuracy: 0.9892\n",
            "Epoch 16/20\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0404 - val_accuracy: 0.9896\n",
            "Epoch 17/20\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0518 - val_accuracy: 0.9872\n",
            "Epoch 18/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0419 - val_accuracy: 0.9888\n",
            "Epoch 19/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.0507 - val_accuracy: 0.9882\n",
            "Epoch 20/20\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0459 - val_accuracy: 0.9888\n",
            "[INFO] normal testing images:\n",
            "[INFO] loss: 0.0459, acc: 0.9888\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a set of adversarial from our test set (so we can evaluate\n",
        "# our model performance *before* and *after* mixed adversarial\n",
        "# training)\n",
        "print(\"[INFO] generating adversarial examples with FGSM...\\n\")\n",
        "(advX, advY) = next(generate_adversarial_batch(model, len(testX),\n",
        "\ttestX, testY, (28, 28, 1), eps=0.1))\n",
        "# re-evaluate the model on the adversarial images\n",
        "(loss, acc) = model.evaluate(x=advX, y=advY, verbose=0)\n",
        "print(\"[INFO] adversarial testing images:\")\n",
        "print(\"[INFO] loss: {:.4f}, acc: {:.4f}\\n\".format(loss, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HNOVmofMB2y",
        "outputId": "50a2a7bc-2a8c-42b8-df3c-ce9468ddbde7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] generating adversarial examples with FGSM...\n",
            "\n",
            "[INFO] adversarial testing images:\n",
            "[INFO] loss: 13.6993, acc: 0.0149\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lower the learning rate and re-compile the model (such that we can\n",
        "# fine-tune it on the mixed batches of normal images and dynamically\n",
        "# generated adversarial images)\n",
        "print(\"[INFO] re-compiling model...\")\n",
        "opt = Adam(lr=1e-4)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "# initialize our data generator to create data batches containing\n",
        "# a mix of both *normal* images and *adversarial* images\n",
        "print(\"[INFO] creating mixed data generator...\")\n",
        "dataGen = generate_mixed_adverserial_batch(model, 64,\n",
        "\ttrainX, trainY, (28, 28, 1), eps=0.1, split=0.5)\n",
        "# fine-tune our CNN on the adversarial images\n",
        "print(\"[INFO] fine-tuning network on dynamic mixed data...\")\n",
        "model.fit(\n",
        "\tdataGen,\n",
        "\tsteps_per_epoch=len(trainX) // 64,\n",
        "\tepochs=10,\n",
        "\tverbose=1)\n",
        "# now that our model is fine-tuned we should evaluate it on the test\n",
        "# set (i.e., non-adversarial) again to see if performance has degraded\n",
        "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
        "print(\"\")\n",
        "print(\"[INFO] normal testing images *after* fine-tuning:\")\n",
        "print(\"[INFO] loss: {:.4f}, acc: {:.4f}\\n\".format(loss, acc))\n",
        "# do a final evaluation of the model on the adversarial images\n",
        "(loss, acc) = model.evaluate(x=advX, y=advY, verbose=0)\n",
        "print(\"[INFO] adversarial images *after* fine-tuning:\")\n",
        "print(\"[INFO] loss: {:.4f}, acc: {:.4f}\".format(loss, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjAhRMpVJhRP",
        "outputId": "8192b93f-ef8a-4171-bbf2-6e505ef80097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] re-compiling model...\n",
            "[INFO] creating mixed data generator...\n",
            "[INFO] fine-tuning network on dynamic mixed data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "937/937 [==============================] - 288s 307ms/step - loss: 1.4661 - accuracy: 0.7649\n",
            "Epoch 2/10\n",
            "937/937 [==============================] - 286s 305ms/step - loss: 0.4212 - accuracy: 0.8823\n",
            "Epoch 3/10\n",
            "937/937 [==============================] - 282s 301ms/step - loss: 0.2989 - accuracy: 0.9102\n",
            "Epoch 4/10\n",
            "937/937 [==============================] - 282s 302ms/step - loss: 0.2304 - accuracy: 0.9273\n",
            "Epoch 5/10\n",
            "937/937 [==============================] - 281s 300ms/step - loss: 0.2010 - accuracy: 0.9377\n",
            "Epoch 6/10\n",
            "937/937 [==============================] - 281s 300ms/step - loss: 0.1770 - accuracy: 0.9445\n",
            "Epoch 7/10\n",
            "937/937 [==============================] - 281s 300ms/step - loss: 0.1610 - accuracy: 0.9496\n",
            "Epoch 8/10\n",
            "937/937 [==============================] - 281s 300ms/step - loss: 0.1482 - accuracy: 0.9525\n",
            "Epoch 9/10\n",
            "937/937 [==============================] - 281s 300ms/step - loss: 0.1405 - accuracy: 0.9553\n",
            "Epoch 10/10\n",
            "937/937 [==============================] - 282s 300ms/step - loss: 0.1285 - accuracy: 0.9592\n",
            "\n",
            "[INFO] normal testing images *after* fine-tuning:\n",
            "[INFO] loss: 0.0309, acc: 0.9904\n",
            "\n",
            "[INFO] adversarial images *after* fine-tuning:\n",
            "[INFO] loss: 0.0960, acc: 0.9692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zsM3-6OWMMY6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}